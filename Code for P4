import requests
from datetime import date
from datetime import datetime
from datetime import timedelta
import re

url = 'https://s3.amazonaws.com/tcmg476/http_access_log'
r = requests.get(url, allow_redirects=True)

with open("python.txt","wb") as textfile:
    for chunk in r.iter_content(chunk_size=1024):

# writing to pdf file
        if chunk:
            textfile.write(chunk)
            result={"total_requests":0,}

# Question 1: requests for each day

with open("python.txt", "r") as textfile:
    first_line = textfile.readlines()[1]
    first_datetime = first_line.split()[3]
    clean_datetime = datetime.strptime(first_datetime, '[%d/%b/%Y:%H:%M:%S')
    first_date = clean_datetime.date()
    
# begins process of extracting date from each line
file = open("python.txt", "r")
count = 0
Q1_dates = 0

for line in file:
    count += 1
    
    # removes lines without date
    if "index.html" in line:
        continue
    
    # searches for datetime and extracts date only
    date_str = re.search('\d{2}/\D{3}/\d{4}', line)
    clean_datetime = datetime.strptime(date_str.group(), '%d/%b/%Y')
    line_date = clean_datetime.date()
    
    delta = timedelta(days=1)
    
    if line_date == first_date:
        Q1_dates += 1
    else: 
        print("There were", Q1_dates, "requests on", first_date)
        Q1_dates = 0
        first_date += delta
        
file.close()
# doesn't print requests for last date




# Question 2a: requests for each week

with open("python.txt", "r") as textfile:
    first_line = textfile.readlines()[1]
    first_datetime = first_line.split()[3]
    clean_datetime = datetime.strptime(first_datetime, '[%d/%b/%Y:%H:%M:%S')
    first_date = clean_datetime.date()
    
# begins process of extracting date from each line
file = open("python.txt", "r")
count = 0
Q2a_dates = 0

for line in file:
    count += 1
    
    # removes lines without date
    if "index.html" in line:
        continue
    
    # searches for datetime and extracts date only
    date_str = re.search('\d{2}/\D{3}/\d{4}', line)
    clean_datetime = datetime.strptime(date_str.group(), '%d/%b/%Y')
    line_date = clean_datetime.date()

    delta = timedelta(weeks=1)
    second_week = first_date + delta
    
    if (line_date == first_date) or (line_date < second_week):
        Q2a_dates += 1
    else: 
        print("There were", Q1_dates, "requests on the week of", first_date.strftime("%b/%d"))
        Q2a_dates = 0
        first_date += delta
        
file.close()

# doesn't print requests for last date
# number of requests don't add up when compared to daily requests




# Question 2b: requests for each month




# Question 3: percentage of unsuccessful requests 

# begins process of extracting date from each line
file = open("python.txt", "r")
count = 0
Q3_lines = 0

for line in file:
    count += 1
    
    # removes lines without status codes
    if "index.html" in line:
        continue
    
    status_codes = line.split()[-2]
    result = status_codes.startswith('4')
    
    if result == True:
        Q3_lines += 1
        
percent = (Q3_lines/total_requests)*100
final_percent = str(round(percent,2))
        
print("Percentage of unsuccessful requests:", final_percent)

file.close()




# Question 4: percentage of successful requests 

# begins process of extracting date from each line
file = open("python.txt", "r")
count = 0
Q4_lines = 0

for line in file:
    count += 1
    
    # removes lines without status codes
    if "index.html" in line:
        continue
    
    status_codes = line.split()[-2]
    result = status_codes.startswith('3')
    
    if result == True:
        Q4_lines += 1
        
percent = (Q4_lines/total_requests)*100
final_percent = str(round(percent,2))
        
print("Percentage of successful requests:", final_percent)

file.close()




# Question 5: the most-requested file

import collections

file = open("python.txt", "r")

clean_log = []

for line in file:
    try:
        clean_log.append(line[line.index("GET")+4:line.index("HTTP")])
    except:
        pass

counter = collections.Counter(clean_log)

for count in counter.most_common(1):
    print("The most-requested file was", str(count[0]) + "and was requested", str(count[1]), "times")

file.close()




# Question 6: the least-requested file

import collections

file = open("python.txt", "r")

clean_log = []

for line in file:
    try:
        clean_log.append(line[line.index("GET")+4:line.index("HTTP")])
    except:
        pass

least_common = collections.Counter(clean_log).most_common()[-1]
print("The least-requested file was", str(least_common[0]) + "and was requested", str(least_common[1]), "time")

file.close()
