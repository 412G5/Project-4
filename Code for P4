### Project 4 by Harley, Lauren, Diego, and Linda
### This code will open and download a specified log file and answer the following questions:
#How many requests were made on each day? 
#How many requests were made on a week-by-week basis? Per month?
#What percentage of the requests were not successful (any 4xx status code)?
#What percentage of the requests were redirected elsewhere (any 3xx codes)?
#What was the most-requested file?
#What was the least-requested file?
#How many requets were made in 6 months
#How many total requests were made


#IMPORTANT THINGS TO RUN BEFORE RUNNING CODE: 
#Make sure that you have all necessary files are downloaded
#Open your preferred terminal and run this:
#IF you're using WINDOWS: py -m pip install requests
#IF you're using MAC: python3 -m pip install requests 
#IF you're using Linux: pip install requests
#That code will allow you to run the request code to get and sort the file logs



import requests
from datetime import date
from datetime import datetime
from datetime import timedelta
import re
import os

if os.path.exists('python.txt') != True: 
    url = 'https://s3.amazonaws.com/tcmg476/http_access_log'
    r = requests.get(url, allow_redirects=True)

    with open("python.txt","wb") as textfile:
        for chunk in r.iter_content(chunk_size=1024):

    # writing to pdf file
            if chunk:
                textfile.write(chunk)
                result={"total_requests":0,}
    print("Download Complete!")

print("Extracting data...")
file = open("python.txt")
total_requests = sum(1 for line in file)




# Question 1: requests for each day

with open("python.txt", "r") as textfile:
    first_line = textfile.readlines()[1]
    first_datetime = first_line.split()[3]
    clean_datetime = datetime.strptime(first_datetime, '[%d/%b/%Y:%H:%M:%S')
    first_date = clean_datetime.date()
    
# begins process of extracting date from each line
file = open("python.txt", "r")
count = 0
Q1_dates = 0

for line in file:
    count += 1
    
    # removes lines without date
    if "index.html" in line:
        continue
    
    # searches for datetime and extracts date only
    date_str = re.search('\d{2}/\D{3}/\d{4}', line)
    clean_datetime = datetime.strptime(date_str.group(), '%d/%b/%Y')
    line_date = clean_datetime.date()
    
    delta = timedelta(days=1)
    
    if line_date == first_date:
        Q1_dates += 1
    else: 
        print("There were", Q1_dates, "requests on", first_date)
        Q1_dates = 0
        first_date += delta
        
file.close()
# doesn't print requests for last date




# Question 2a: requests for each week

with open("python.txt", "r") as textfile:
    first_line = textfile.readlines()[1]
    first_datetime = first_line.split()[3]
    clean_datetime = datetime.strptime(first_datetime, '[%d/%b/%Y:%H:%M:%S')
    first_date = clean_datetime.date()
    
# begins process of extracting date from each line
file = open("python.txt", "r")
count = 0
Q2a_dates = 0

for line in file:
    count += 1
    
    # removes lines without date
    if "index.html" in line:
        continue
    
    # searches for datetime and extracts date only
    date_str = re.search('\d{2}/\D{3}/\d{4}', line)
    clean_datetime = datetime.strptime(date_str.group(), '%d/%b/%Y')
    line_date = clean_datetime.date()

    delta = timedelta(weeks=1)
    second_week = first_date + delta
    
    if (line_date == first_date) or (line_date < second_week):
        Q2a_dates += 1
    else: 
        print("There were", Q2a_dates, "requests on the week of", first_date.strftime("%b/%d"))
        Q2a_dates = 0
        first_date += delta
        
file.close()

# doesn't print requests for last date


# Question 2b: requests for each month



# Question 3: percentage of unsuccessful requests 

# begins process of extracting date from each line
file = open("python.txt", "r")
count = 0
Q3_lines = 0

for line in file:
    count += 1
    
    # removes lines without status codes
    if "index.html" in line:
        continue
    
    status_codes = line.split()[-2]
    result = status_codes.startswith('4')
    
    if result == True:
        Q3_lines += 1
        
percent = (Q3_lines/total_requests)*100
final_percent = str(round(percent,2))
        
print("Percentage of unsuccessful requests:", final_percent)

file.close()




# Question 4: percentage of redirected requests

# begins process of extracting date from each line
file = open("python.txt", "r")
count = 0
Q4_lines = 0

for line in file:
    count += 1
    
    # removes lines without status codes
    if "index.html" in line:
        continue
    
    status_codes = line.split()[-2]
    result = status_codes.startswith('3')
    
    if result == True:
        Q4_lines += 1
        
percent = (Q4_lines/total_requests)*100
final_percent = str(round(percent,2))
        
print("Percentage of redirected requests:", final_percent)

file.close()




# Question 5: the most-requested file

import collections

file = open("python.txt", "r")

clean_log = []

for line in file:
    try:
        clean_log.append(line[line.index("GET")+4:line.index("HTTP")])
    except:
        pass

counter = collections.Counter(clean_log)

for count in counter.most_common(1):
    print("The most-requested file was", str(count[0]) + "and was requested", str(count[1]), "times")

file.close()




# Question 6: the least-requested file

import collections

file = open("python.txt", "r")

clean_log = []

for line in file:
    try:
        clean_log.append(line[line.index("GET")+4:line.index("HTTP")])
    except:
        pass

least_common = collections.Counter(clean_log).most_common()[-1]
print("The least-requested file was", str(least_common[0]) + "and was requested", str(least_common[1]), "time")

file.close()
